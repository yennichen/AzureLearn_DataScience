{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "WorkspaceException",
     "evalue": "WorkspaceException:\n\tMessage: Workspace with name 'AMLWorkspace' already exists under resource group with name 'rgAMLSLearnworkspace'.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Workspace with name 'AMLWorkspace' already exists under resource group with name 'rgAMLSLearnworkspace'.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWorkspaceException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ad64cc31387c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mresource_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rgAMLSLearnworkspace'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mcreate_resource_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'eastus2'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Workspace is built\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\AppData\\anaconda3\\lib\\site-packages\\azureml\\core\\workspace.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(name, auth, subscription_id, resource_group, location, create_resource_group, sku, friendly_name, storage_account, key_vault, app_insights, container_registry, default_cpu_compute_target, default_gpu_compute_target, exist_ok, show_output)\u001b[0m\n\u001b[0;32m    414\u001b[0m                                         \u001b[0mdefault_cpu_compute_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_cpu_compute_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                                         \u001b[0mdefault_gpu_compute_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_gpu_compute_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m                                         exist_ok=exist_ok, show_output=show_output)\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\AppData\\anaconda3\\lib\\site-packages\\azureml\\core\\workspace.py\u001b[0m in \u001b[0;36m_create_legacy\u001b[1;34m(auth, subscription_id, resource_group_name, workspace_name, location, create_resource_group, sku, friendly_name, storage_account, key_vault, app_insights, container_registry, default_cpu_compute_target, default_gpu_compute_target, exist_ok, show_output)\u001b[0m\n\u001b[0;32m   1048\u001b[0m                                                                \u001b[0mdefault_cpu_compute_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_cpu_compute_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m                                                                \u001b[0mdefault_gpu_compute_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_gpu_compute_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m                                                                exist_ok=exist_ok, show_output=show_output)\n\u001b[0m\u001b[0;32m   1051\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mworkspace_object_autorest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mWorkspaceException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Couldn't create the workspace.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\AppData\\anaconda3\\lib\\site-packages\\azureml\\_project\\_commands.py\u001b[0m in \u001b[0;36mcreate_workspace\u001b[1;34m(auth, resource_group_name, workspace_name, subscription_id, location, create_resource_group, sku, friendly_name, storage_account, key_vault, app_insights, containerRegistry, default_cpu_compute_target, default_gpu_compute_target, exist_ok, show_output)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[0mshow_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         sku=sku)\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\AppData\\anaconda3\\lib\\site-packages\\azureml\\_workspace\\custom.py\u001b[0m in \u001b[0;36mml_workspace_create_resources\u001b[1;34m(auth, client, resource_group_name, workspace_name, location, subscription_id, friendly_name, storage_account, key_vault, app_insights, containerRegistry, default_cpu_compute_target, default_gpu_compute_target, exist_ok, show_output, sku)\u001b[0m\n\u001b[0;32m     53\u001b[0m             raise WorkspaceException(\"Workspace with name '{0}' already exists under\"\n\u001b[0;32m     54\u001b[0m                                      \" resource group with name '{1}'.\".format(workspace_name,\n\u001b[1;32m---> 55\u001b[1;33m                                                                                resource_group_name))\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mErrorResponseWrapperException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresponse_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m404\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWorkspaceException\u001b[0m: WorkspaceException:\n\tMessage: Workspace with name 'AMLWorkspace' already exists under resource group with name 'rgAMLSLearnworkspace'.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Workspace with name 'AMLWorkspace' already exists under resource group with name 'rgAMLSLearnworkspace'.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "# Create a new workspace\n",
    "from azureml.core import Workspace, Experiment, Run\n",
    "\n",
    "#subscription_id='{azure-subscription-id}'\n",
    "ws = Workspace.create(\n",
    "            name = 'AMLWorkspace',\n",
    "            subscription_id='485f9fa6-0221-4dbf-8074-a202426a29bf', \n",
    "            resource_group='rgAMLSLearnworkspace',\n",
    "            create_resource_group=True,\n",
    "            location='eastus2'\n",
    ")\n",
    "print(\"Workspace is built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use an existed workspace\n",
    "ws = Workspace.get(name=\"AMLWorkspace\",\n",
    "               subscription_id='485f9fa6-0221-4dbf-8074-a202426a29bf',\n",
    "               resource_group='rgAMLSLearnworkspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute target created\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Build a remote compute target\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# Step 1-1: name the cluster and set the minimal and maximal number of nodes \n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\")\n",
    "min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 3)\n",
    "\n",
    "# Step 1-2: choose environment variables \n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "provisioning_config = AmlCompute.provisioning_configuration(\n",
    "    vm_size = vm_size, min_nodes = min_nodes, max_nodes = max_nodes)\n",
    "\n",
    "# create the cluster\n",
    "compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "print('Compute target created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "#create a folder for the dataset\n",
    "os.makedirs('./data', exist_ok = True)\n",
    "\n",
    "# load dataset to the directory--as you can see, you must load train sets and test sets separately\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename='./data/train-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename='./data/train-labels.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename='./data/test-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename='./data/test-labels.gz')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 4 files\n",
      "Uploading ./data\\test-images.gz\n",
      "Uploading ./data\\test-labels.gz\n",
      "Uploading ./data\\train-images.gz\n",
      "Uploading ./data\\train-labels.gz\n",
      "Uploaded ./data\\test-labels.gz, 1 files out of an estimated total of 4\n",
      "Uploaded ./data\\train-labels.gz, 2 files out of an estimated total of 4\n",
      "Uploaded ./data\\test-images.gz, 3 files out of an estimated total of 4\n",
      "Uploaded ./data\\train-images.gz, 4 files out of an estimated total of 4\n",
      "Uploaded 4 files\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Upload data to workspace by using get_default_datastore()\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data', target_path='mnist', overwrite=True, show_progress=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create a folder to save the code\n",
    "import os\n",
    "\n",
    "# create the folder\n",
    "folder_training_script = './trial_model_mnist'\n",
    "os.makedirs(folder_training_script, exist_ok=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./trial_model_mnist/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_training_script/train.py\n",
    "# '%%writefile' should always be the first line of code in a cell\n",
    "\n",
    "\n",
    "# Finally, let's prepare our model training script (note that in this script, you are defining two parameters):\n",
    "# The first parameter is for finding the data in the cloud or for setting the path to the data.\n",
    "# The other parameter is the regularization parameter in the algorithm.\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from azureml.core import Run\n",
    "# from utils import load_data\n",
    "\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "# load compressed MNIST gz files and return numpy arrays\n",
    "def load_data(filename, label=False):\n",
    "    with gzip.open(filename) as gz:\n",
    "        struct.unpack('I', gz.read(4))\n",
    "        n_items = struct.unpack('>I', gz.read(4))\n",
    "        if not label:\n",
    "            n_rows = struct.unpack('>I', gz.read(4))[0]\n",
    "            n_cols = struct.unpack('>I', gz.read(4))[0]\n",
    "            res = np.frombuffer(gz.read(n_items[0] * n_rows * n_cols), dtype=np.uint8)\n",
    "            res = res.reshape(n_items[0], n_rows * n_cols)\n",
    "        else:\n",
    "            res = np.frombuffer(gz.read(n_items[0]), dtype=np.uint8)\n",
    "            res = res.reshape(n_items[0], 1)\n",
    "    return res\n",
    "\n",
    "\n",
    "# let user feed in 2 parameters, the dataset to mount or download, and the regularization rate of the logistic regression model\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--regularization', type=float, dest='reg', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "###\n",
    "data_folder = os.path.join(args.data_folder, 'mnist')\n",
    "print('Data folder:', data_folder)\n",
    "\n",
    "# load the train and test set into numpy arrays\n",
    "X_train = load_data(os.path.join(data_folder, 'train-images.gz'), False) / 255.0\n",
    "X_test = load_data(os.path.join(data_folder, 'test-images.gz'), False) / 255.0\n",
    "\n",
    "#print variable set dimension\n",
    "print(X_train.shape, X_test.shape, sep = '\\n')\n",
    "\n",
    "y_train = load_data(os.path.join(data_folder, 'train-labels.gz'), True).reshape(-1)\n",
    "y_test = load_data(os.path.join(data_folder, 'test-labels.gz'), True).reshape(-1)\n",
    "\n",
    "#print the response variable dimension\n",
    "print( y_train.shape, y_test.shape, sep = '\\n')\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "print('Train a logistic regression model with regularization rate of', args.reg)\n",
    "clf = LogisticRegression(C=1.0/args.reg, solver=\"liblinear\", multi_class=\"auto\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Predict the test set')\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "# calculate accuracy on the prediction\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy is', acc)\n",
    "\n",
    "run.log('regularization rate', np.float(args.reg))\n",
    "run.log('accuracy', np.float(acc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=clf, filename='outputs/sklearn_mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the last line of the training script saves the model as a pickle file in the outputs folder of the experiment workspace. You use this pickle file later to deploy the model.\n",
    "\n",
    "An estimator object is used to submit the run. Create your estimator by running the following code to define:\n",
    "\n",
    "*The name of the estimator object, est.\n",
    "\n",
    "*The directory that contains your scripts. All the files in this directory are uploaded into the cluster nodes for running.\n",
    "\n",
    "*The compute target. In this case, you use the Azure Machine Learning compute cluster that you created.\n",
    "\n",
    "*The training script name, train.py.\n",
    "\n",
    "*Parameters that the training script requires.\n",
    "\n",
    "*Python packages that are necessary for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - You have specified to install packages in your run. Note that you have overridden Azure ML's installation of the following packages: ['scikit-learn']. We cannot guarantee image build will succeed.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--regularization': 0.5\n",
    "}\n",
    "\n",
    "#import the Scikit-learn package \n",
    "est = SKLearn(source_directory=folder_training_script,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                conda_packages=['scikit-learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment created\n"
     ]
    }
   ],
   "source": [
    "# Submit the model, monitor the run, and retrieve the results\n",
    "\n",
    "# We need to create an Experiment to run the model training in.\n",
    "from azureml.core import Experiment\n",
    "\n",
    "#Create an experiment\n",
    "experiment = Experiment(workspace = ws, name = \"amls-learn-experimentnew5\")\n",
    "\n",
    "print('Experiment created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>amls-learn-experimentnew5</td><td>amls-learn-experimentnew5_1573047922_07279594</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/experiments/amls-learn-experimentnew5/runs/amls-learn-experimentnew5_1573047922_07279594?wsid=/subscriptions/485f9fa6-0221-4dbf-8074-a202426a29bf/resourcegroups/rgAMLSLearnworkspace/workspaces/AMLWorkspace\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: amls-learn-experimentnew5,\n",
       "Id: amls-learn-experimentnew5_1573047922_07279594,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The last step is running the model. Sign in with your Azure account if prompted to do so.\n",
    "run = experiment.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml.widgets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-c4a5c90b2c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# You could use the widgets module from the azureml package to monitor your run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azureml.widgets'"
     ]
    }
   ],
   "source": [
    "# You could use the widgets module from the azureml package to monitor your run\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# After this run finishes, you can print the results. \n",
    "# The results were logged because you wrote the code in the training script.\n",
    "\n",
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
